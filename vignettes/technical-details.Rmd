---
title: "Technical Details"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Technical Details}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette describes the mathematical framework and computational implementation of the JointODE model, which jointly models longitudinal biomarker trajectories and survival outcomes through a coupled ordinary differential equation (ODE) system.

## Model Framework

### Longitudinal Sub-Model

The observed biomarker measurements are modeled as:

$$V_{ij}=m_i(T_{ij})+b_i+\varepsilon_{ij},\quad i=1,\ldots,n,\quad j=1,\ldots,n_i$$

where:

-   $V_{ij}$: Observed biomarker value for subject $i$ at time $T_{ij}$
-   $m_i(t)$: True underlying biomarker trajectory
-   $b_i\sim\mathcal{N}(0,\sigma_{b}^{2})$: Subject-specific random intercept
-   $\varepsilon_{ij}\sim\mathcal{N}(0,\sigma_{e}^{2})$: Measurement error

The biomarker trajectory evolution is characterized by the following second-order differential equation:

$$
\ddot{m}_i(t) = f\big(m_i(t), \dot{m}_i(t), \mathbf{X}_i(t), t\big)
$$

where $f: \mathbb{R} \times \mathbb{R} \times \mathbb{R}^p \times \mathbb{R}^+ \to \mathbb{R}$ is a smooth function modeling the biomarker acceleration as a function of its current value $m_i(t)$, velocity $\dot{m}_i(t)$, time-varying covariates $\mathbf{X}_i(t) \in \mathbb{R}^p$, and time $t$.

### Survival Sub-Model

The hazard function incorporates biomarker dynamics:

$$
\lambda_i(t) = \lambda_{0}(t)\exp\left[\mathbf{W}_i^{\top}\boldsymbol{\phi}+\mathbf{m}_i(t)^{\top}\boldsymbol{\alpha}+b_{i}\right]
$$

where:

-   $\lambda_{0}(t)$: Baseline hazard (e.g., Weibull, piecewise constant)
-   $\mathbf{m}_i(t)=\left(m_i(t), \dot{m}_i(t)\right)^{\top}$: Biomarker value and derivatives
-   $\boldsymbol{\alpha}=(\alpha_1, \alpha_2)^{\top}$: Association parameters for value and velocity
-   $\mathbf{W}_i$: Baseline covariates with coefficients $\boldsymbol{\phi}$
-   $b_i$: Subject-specific random intercept

### ODE System

The complete system couples the biomarker trajectory dynamics with the survival process. The state vector $\mathbf{s}_i(t) = (\Lambda_i(t), m_i(t), \dot{m}_i(t))^{\top}$ evolves according to:

$$
\frac{d\mathbf{s}_i}{dt} = \begin{pmatrix}
\lambda_i(t|b_i) \\
\dot{m}_i(t) \\
f(m_i(t), \dot{m}_i(t), \mathbf{X}_i(t), t)
\end{pmatrix}
$$

with initial conditions $\mathbf{s}_i(0) = (0, m_{i0}, \dot{m}_{i0})^{\top}$, where $m_{i0}$ and $\dot{m}_{i0}$ are the initial biomarker value and velocity for subject $i$.

## Statistical Inference

For parameter estimation, we need to specify parametric forms for the model components.

### Model Parameterization

**Hazard Function:**
We parameterize the log baseline hazard using B-splines:

$$\log\lambda_0(t) = \boldsymbol{\eta}^{\top} \mathbf{B}^{(\lambda)}(t)$$

Thus, the full hazard function becomes:

$$\lambda_i(t|b_i) = \exp\left[\boldsymbol{\eta}^{\top} \mathbf{B}^{(\lambda)}(t) + \mathbf{W}_i^{\top}\boldsymbol{\phi} + \mathbf{m}_i(t)^{\top}\boldsymbol{\alpha} + b_{i}\right]$$

where $\mathbf{B}^{(\lambda)}(t)$ is the B-spline basis for the log baseline hazard, and $\boldsymbol{\eta}$ are the corresponding coefficients.

**Acceleration Function:**
To make the model tractable, we approximate the unknown acceleration function $f$ using a linear model:

$$f(m_i(t), \dot{m}_i(t), \mathbf{X}_i(t), t) \approx \boldsymbol{\beta}^{\top}\mathbf{Z}_i(t)$$

where:

- $\mathbf{Z}_i(t) = [m_i(t), \dot{m}_i(t), \mathbf{X}_i^{\top}(t), t]^{\top}$ is the feature vector
- $\boldsymbol{\beta}$ are the linear coefficients (no constraints needed)

### Likelihood

The joint likelihood for subject $i$ integrates over the random effect:

$$L_i(\boldsymbol{\theta}) = \int p(\mathbf{V}_i | b_i) \cdot p(T_i, \delta_i | b_i) \cdot p(b_i) \, db_i$$

where $\boldsymbol{\theta} = (\boldsymbol{\eta}, \boldsymbol{\phi}, \boldsymbol{\alpha}, \boldsymbol{\beta}, \sigma_e^2, \sigma_b^2)$.

**Likelihood Components:**

1. **Longitudinal:**
   $$p(\mathbf{V}_i | b_i) = \prod_{j=1}^{n_i} \mathcal{N}(V_{ij}; m_i(T_{ij}) + b_i, \sigma_e^2)$$

2. **Survival:**
   $$p(T_i, \delta_i | b_i) = [\lambda_i(T_i|b_i)]^{\delta_i} \exp[-\Lambda_i(T_i|b_i)]$$

3. **Random Effect:**
   $$p(b_i) \sim \mathcal{N}(0, \sigma_b^2)$$

### Parameter Estimation

For the linear acceleration model, we use direct gradient-based optimization of the marginal likelihood.

#### Posterior Computation

For each subject $i$, compute the posterior distribution of $b_i$ given observed data $\mathcal{O}_i$.

**Key simplification:** The hazard and cumulative hazard factor as:

- $\lambda_i(t|b_i) = e^{b_i} \lambda_i(t|0)$
- $\Lambda_i(t|b_i) = e^{b_i} \Lambda_i(t|0)$

**Implementation:**

1. **Solve baseline ODE** with $b_i = 0$ to obtain $m_i(t)$, $\lambda_i(t|0)$, $\Lambda_i(T_i|0)$
2. **Find posterior mode** $\tilde{b}_i$ by maximizing:
   $$\ell_i(b) = b\left[\frac{S_i}{\sigma_e^2} + \delta_i\right] - \frac{b^2}{2}\left[\frac{n_i}{\sigma_e^2} + \frac{1}{\sigma_b^2}\right] - e^b\Lambda_i(T_i|0)$$
   where $S_i = \sum_j(V_{ij} - m_i(T_{ij}))$
3. **Compute posterior moments** via adaptive Gauss-Hermite quadrature:
   - Mean: $\hat{b}_i = E[b_i|\mathcal{O}_i]$
   - Variance: $\hat{v}_i = \text{Var}[b_i|\mathcal{O}_i]$
   - Transform: $E[e^{b_i}|\mathcal{O}_i]$ for survival updates

#### Objective Function

We maximize the expected complete-data log-likelihood:

$$Q(\boldsymbol{\theta}) = Q_{\text{long}} + Q_{\text{surv}} + Q_{\text{RE}}$$

where:

- $Q_{\text{long}} = -\frac{1}{2\sigma_e^2}\sum_{i,j} [(V_{ij} - m_i(T_{ij}) - \hat{b}_i)^2 + \hat{v}_i] - \frac{N}{2}\log(2\pi\sigma_e^2)$, where $N = \sum_{i=1}^n n_i$ is the total number of observations
- $Q_{\text{surv}} = \sum_i [\delta_i(\log\lambda_i(T_i|0) + \hat{b}_i) - E[e^{b_i}|\mathcal{O}_i]\Lambda_i(T_i|0)]$
- $Q_{\text{RE}} = -\frac{1}{2\sigma_b^2}\sum_i (\hat{b}_i^2 + \hat{v}_i) - \frac{n}{2}\log(2\pi\sigma_b^2)$

**Optimization Strategy:**

We optimize all parameters $\boldsymbol{\theta}$ using gradient-based methods:

$$
\hat{\boldsymbol{\theta}} = \arg\max_{\boldsymbol{\theta}} Q(\boldsymbol{\theta})
$$

The variance components are updated using closed-form expressions:
$$
\sigma_e^2 = \frac{1}{N}\sum_{i,j}[(V_{ij} - m_i(T_{ij}) - \hat{b}_i)^2 + \hat{v}_i],\quad\sigma_b^2 = \frac{1}{n}\sum_i(\hat{b}_i^2 + \hat{v}_i)
$$

## Computational Details

### Overview of Gradient Computation

The optimization requires maximization of the expected complete-data log-likelihood $Q(\boldsymbol{\theta})$ with respect to the parameter vector $\boldsymbol{\theta} = (\boldsymbol{\eta}, \boldsymbol{\phi}, \boldsymbol{\alpha}, \boldsymbol{\beta}, \sigma_e^2, \sigma_b^2)$. To perform this optimization efficiently, gradient-based methods necessitate the computation of:

$$\nabla_{\boldsymbol{\theta}} Q = \sum_{i=1}^{n}\sum_{j=1}^{n_i} \frac{r_{ij}}{\sigma_e^2} \frac{\partial m_i(T_{ij})}{\partial \boldsymbol{\theta}} + \sum_{i=1}^{n} \left[\delta_i \frac{\partial \log\lambda_i(T_i|0)}{\partial \boldsymbol{\theta}} - E[e^{b_i}|\mathcal{O}_i] \frac{\partial \Lambda_i(T_i|0)}{\partial \boldsymbol{\theta}}\right]$$

where $r_{ij} = V_{ij} - m_i(T_{ij}) - \hat{b}_i$ denotes the residual between observed and fitted longitudinal values.

This gradient formula reveals the fundamental computational challenge: we must evaluate the sensitivities of both the biomarker trajectory $m_i(t)$ and the hazard functions with respect to all model parameters. Specifically, we require:

- $\frac{\partial m_i(T_{ij})}{\partial \boldsymbol{\theta}}$: trajectory sensitivities at observation times
- $\frac{\partial \log\lambda_i(T_i|0)}{\partial \boldsymbol{\theta}}$: log hazard sensitivities at event times
- $\frac{\partial \Lambda_i(T_i|0)}{\partial \boldsymbol{\theta}}$: cumulative hazard sensitivities at event times

These sensitivities depend on the solution of the nonlinear second-order ODE system and cannot be derived in closed form. We first present the explicit forms of these gradients, then discuss numerical methods for their computation.

### Explicit Forms of Gradient Components

The parameter vector $\boldsymbol{\theta} = (\boldsymbol{\eta}, \boldsymbol{\phi}, \boldsymbol{\alpha}, \boldsymbol{\beta})$ includes the hazard model parameters and the linear acceleration coefficients. We derive the gradient with respect to each component.

#### Gradient Components

The gradient components decompose as follows:

**Baseline hazard coefficients** ($\boldsymbol{\eta}$):

$$\nabla_{\boldsymbol{\eta}} Q = \sum_{i=1}^{n} \left[\delta_i \mathbf{B}^{(\lambda)}(T_i) - E[e^{b_i}|\mathcal{O}_i] \frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\eta}}\right]$$

**Baseline covariate effects** ($\boldsymbol{\phi}$):

$$\nabla_{\boldsymbol{\phi}} Q = \sum_{i=1}^{n} \left[\delta_i - E[e^{b_i}|\mathcal{O}_i] \cdot \Lambda_i(T_i|0)\right] \mathbf{W}_i$$

**Association parameters** ($\boldsymbol{\alpha}$):

$$\nabla_{\boldsymbol{\alpha}} Q = \sum_{i=1}^{n} \left[\delta_i \mathbf{m}_i(T_i) - E[e^{b_i}|\mathcal{O}_i] \frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\alpha}}\right]$$

#### Gradient with Respect to Linear Acceleration Coefficients $\boldsymbol{\beta}$

The gradient with respect to the linear acceleration coefficients is:

$$\nabla_{\boldsymbol{\beta}} Q = \sum_{i=1}^{n}\sum_{j=1}^{n_i} \frac{r_{ij}}{\sigma_e^2} \frac{\partial m_i(T_{ij})}{\partial \boldsymbol{\beta}} + \sum_{i=1}^{n} \left[\delta_i \boldsymbol{\alpha}^{\top} \frac{\partial \mathbf{m}_i(T_i)}{\partial \boldsymbol{\beta}} - E[e^{b_i}|\mathcal{O}_i] \frac{\partial \Lambda_i(T_i|0)}{\partial \boldsymbol{\beta}}\right]$$

where $r_{ij} = V_{ij} - m_i(T_{ij}) - \hat{b}_i$ denotes the residual between observed and fitted values.

### Computing the Required Sensitivities

The gradient expressions above involve two types of sensitivities that must be computed numerically:

#### Cumulative Hazard Sensitivities

The cumulative hazard function $\Lambda_i(T_i|0)$ depends on parameters through the instantaneous hazard. For parameters affecting the hazard directly, the sensitivities are computed as:

$$
\frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\eta}}=\int_{0}^{T_i}\lambda_i(t|0)\mathbf{B}^{(\lambda)}(t)\,\mathrm{d}t,\quad
\frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\alpha}}=\int_{0}^{T_i}\lambda_i(t|0)\mathbf{m}_i(t)\,\mathrm{d}t,\quad
\frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\phi}}=\int_{0}^{T_i}\lambda_i(t|0)\mathbf{W}_i\,\mathrm{d}t
$$

For parameters affecting the trajectory $m_i(t)$, the chain rule yields:

$$
\frac{\partial\Lambda_i(T_i|0)}{\partial\boldsymbol{\beta}}=\int_{0}^{T_i}\lambda_i(t|0)\boldsymbol{\alpha}^{\top}\frac{\partial\mathbf{m}_i(t)}{\partial\boldsymbol{\beta}}\,\mathrm{d}t
$$

##### Trajectory Sensitivities

The trajectory sensitivities with respect to parameters affecting the ODE system are more complex and must be computed numerically. These sensitivities satisfy the following relationships:

**For single-index coefficients ($\boldsymbol{\beta}$):**

The trajectory sensitivities evolve according to:

$$
\frac{\partial m_i(t)}{\partial \boldsymbol{\beta}} = \int_{0}^{t} \frac{\partial\dot{m}_i(s)}{\partial \boldsymbol{\beta}} \,\mathrm{d}s,\quad
\frac{\partial\dot{m}_i(t)}{\partial \boldsymbol{\beta}} = \int_{0}^{t} \frac{\partial \ddot{m}_i(s)}{\partial \boldsymbol{\beta}} \,\mathrm{d}s
$$

where the acceleration sensitivity is given by:

$$
\frac{\partial \ddot{m}_i(t)}{\partial \boldsymbol{\beta}} = \mathbf{Z}_i(t) + \boldsymbol{\beta}^{\top} \frac{\partial \mathbf{Z}_i(t)}{\partial\boldsymbol{\beta}}
$$

Here, $\mathbf{Z}_i(t) = [m_i(t), \dot{m}_i(t), \mathbf{X}_i^{\top}(t), t]^{\top}$ is the feature vector. Since the acceleration is now linear in $\boldsymbol{\beta}$, we have:

$$\frac{\partial \mathbf{Z}_i(t)}{\partial\boldsymbol{\beta}} = \begin{bmatrix}
\frac{\partial m_i(t)}{\partial \boldsymbol{\beta}} \\ \frac{\partial \dot{m}_i(t)}{\partial \boldsymbol{\beta}} \\ \mathbf{0} \\ 0
\end{bmatrix}$$

where the covariates $\mathbf{X}_i(t)$ and time $t$ do not depend on $\boldsymbol{\beta}$.



### Numerical Methods for Sensitivity Computation

For the linear acceleration model, the sensitivities can be computed more efficiently. Two computational strategies are available:

1. **Forward Sensitivity Method**: Augments the original ODE system with sensitivity equations that are integrated simultaneously with the state equations
2. **Adjoint Method**: Solves a backward-in-time adjoint system, offering computational advantages when the number of parameters exceeds the number of objective function evaluations

#### Forward Sensitivity Method

The forward method extends the original three-dimensional state space to include sensitivity trajectories, solving augmented ODE systems that simultaneously evolve both the primary state variables and their parameter sensitivities.

**Augmented system:**

$$\frac{d}{dt}\begin{bmatrix}
\Lambda_i \\ m_i \\ \dot{m}_i \\ \partial\Lambda_{\eta,i} \\ \partial\Lambda_{\alpha,i} \\ \partial m_{i,\beta} \\ \partial\dot{m}_{i,\beta} \\ \partial\Lambda_{\beta,i}
\end{bmatrix} = \begin{bmatrix}
\lambda_i(t|0) \\
\dot{m}_i(t) \\
\boldsymbol{\beta}^{\top}\mathbf{Z}_i(t) \\
\mathbf{B}^{(\lambda)}(t) \lambda_i(t|0) \\
\mathbf{m}_i(t) \lambda_i(t|0) \\
\partial \dot{m}_{i,\beta} \\
\mathbf{Z}_i(t) + \boldsymbol{\beta}^{\top} \frac{\partial \mathbf{Z}_i(t)}{\partial\boldsymbol{\beta}} \\
\boldsymbol{\alpha}^{\top}\frac{\partial\mathbf{m}_i(t)}{\partial\boldsymbol{\beta}} \cdot \lambda_i(t|0)
\end{bmatrix}$$

Note that $\partial\Lambda_{\phi,i} = 0$ since the survival covariates $\mathbf{W}_i$ do not affect the trajectory dynamics.

Here, $\partial\Lambda_{\eta,i}$, $\partial\Lambda_{\alpha,i}$, and $\partial\Lambda_{\beta,i}$ denote the cumulative hazard sensitivities with respect to the corresponding parameter groups. This single augmented system must be integrated from $t=0$ to $t=T_i$ for each subject to obtain the complete sensitivity information required for gradient computation.

#### Adjoint Method

The adjoint method provides an alternative, more memory-efficient approach for computing gradients, particularly advantageous when the number of parameters substantially exceeds the number of objective function components. Instead of propagating sensitivities forward in time, this method solves a backward-in-time adjoint system.

**Mathematical Foundation**

Given the ODE system $\frac{d\mathbf{s}}{dt} = F(t, \mathbf{s}; \boldsymbol{\theta})$ with $\mathbf{s}(0) = \mathbf{s}_0$, we derive the adjoint sensitivity formula.

Since $\mathbf{s}(t)$ satisfies the ODE, for any function $\boldsymbol{\kappa}(t)$:
$$\mathbf{s}(T) = \mathbf{s}(T) - \int_0^T \boldsymbol{\kappa}^{\top} \left[\frac{d\mathbf{s}}{dt} - F\right] dt$$

Differentiating with respect to $\boldsymbol{\theta}$ and using integration by parts:
$$\frac{\partial \mathbf{s}(T)}{\partial \boldsymbol{\theta}} = \int_0^T \boldsymbol{\kappa}^{\top} \frac{\partial F}{\partial \boldsymbol{\theta}} dt - \boldsymbol{\kappa}(T)^{\top} \frac{\partial \mathbf{s}(T)}{\partial \boldsymbol{\theta}} + \int_0^T \left[\frac{d\boldsymbol{\kappa}}{dt} + \left(\frac{\partial F}{\partial \mathbf{s}}\right)^{\top} \boldsymbol{\kappa}\right]^{\top} \frac{\partial \mathbf{s}}{\partial \boldsymbol{\theta}} dt$$

Define $\tilde{\boldsymbol{\kappa}} = \boldsymbol{\kappa} + \mathbf{e}_k$ and choose it to satisfy:
$$\frac{d\tilde{\boldsymbol{\kappa}}}{dt} = -\left(\frac{\partial F}{\partial \mathbf{s}}\right)^{\top} \tilde{\boldsymbol{\kappa}}, \quad \tilde{\boldsymbol{\kappa}}(T) = \mathbf{e}_k$$

This choice eliminates the $\frac{\partial \mathbf{s}}{\partial \boldsymbol{\theta}}$ terms, yielding:
$$\frac{\partial \mathbf{s}_k(T)}{\partial \boldsymbol{\theta}} = \int_0^T \tilde{\boldsymbol{\kappa}}^{\top} \frac{\partial F}{\partial \boldsymbol{\theta}}\bigg|_{\mathbf{s}} dt$$

where $\mathbf{e}_k$ is the $k$-th unit vector (i.e., a vector with 1 in the $k$-th position and 0 elsewhere).
